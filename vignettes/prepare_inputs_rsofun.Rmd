---
title: "Prepare rsofun forcing data"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

The following describes how to use the [ingestr R package](https://stineb.github.io/ingestr/) for collecting rsofun forcing data. This is to create the object `df_drivers`, required as an input (forcing) to rsofun. rsofun is designed for site-level (point-scale) simulations and is scalable (parallelised, using \*multidplyr\*), enabling large ensemble simulations.

This vignette describes forcing data collection for two typical cases of site ensemble simulations:

-   Ensemble simulations for a \*\*network\*\* of sites, where specifically formatted site-level climate forcing data is provided, e.g., FLUXNET simulations.

-   Ensemble simulations for \*\*"no-network"\*\* sites, i.e., where no site-specific environmental forcing data is provided. In this case, climate forcing data is read from global maps, given the geographical location of sites.

This vignette is specific for collecting forcing data where no site-specific measurements are available, but all data is extracted from global maps. Head over to the vignette `prepare_fluxnetinputs_rsofun.Rmd` for an example for collecting forcing data for a FLUXNET site, using site-specific meteorological data. Note that this code requires the [tidyverse](https://www.tidyverse.org/) R package.

We need the following two packages:

```{r}
library(ingestr)
library(tidyverse)
```

Get the package [ingestr](https://stineb.github.io/ingestr/) from github by

```{r eval=FALSE}
devtools::install_github("stineb/ingestr")
```

## Site selection and meta data

In both cases, a small number of meta data variables have to be specified for each site to define site meta information. This information is also used for input, calibration, and evaluation data ingestion. Required meta information is specified as a data frame with sites along rows and the following variables (by columns):

-   `sitename`: any unique identifying of the site(s)
-   `lat` for latitude (decimal degrees)
-   `lon` for longitude (decimal degrees) - this is only used for data ingestion but not for the P-model simulation with `rsofun`.
-   `elv` for elevation (m a.s.l.). If this is not known, *ingestr* may be used to extract information from a digital elevation model.
-   `year_start` and `year_end` specifying years covered by the simulation. Data extraction and model simulations always cover all 365 days of each year.
-   `whc` for the total rooting zone soil water holding capacity. This is not a temporary "fudge" solution. Set it to 170 mm if no better information is available.
-   `koeppen_code` to group sites for evaluation by Koeppen-Geiger climate zones (may be ignored, only required for `eval_sofun()`).

The next few steps are described below, distinguishing the two cases (network, vs. no-network site ensemble).

## No-network site ensemble

The following is an example for an ensemble of simulations of three arbitrarily located sites.

```{r}
siteinfo <- tibble(
  sitename = c("site_rsofun_demo_1", "site_rsofun_demo_2", "site_rsofun_demo_3"),
  lon = c(100.05, 100.45, 90),
  lat = c(50, 50, 50),
  elv = c(1000, 250, 2500),
  year_start = c(2003, 2001, 2005),
  year_end = c(2005, 2006, 2007),
  whc = 200
)
siteinfo
```

Note that sites "s1" and "s2" are located close to each other - within 0.5 degrees in longitude and on the same latitude. Climate forcing used in this example (see below) is from the WATCH-WFDEI reanalysis data, provided at 0.5 degrees. This implies that sites "s1" and "s2" are forced with the same climate (but different fAPAR data). To speed up climate data ingest, we can determine the 0.5 degrees gridcells containing at least one site and ingest respective data. These steps are explained in Section *Forcing by gridcell*. Below, we continue explaining simulations with forcing by site. This facilitates the coding (while dealing with larger amount of climate forcing data, which slows it down) ...

Input data, used as model forcing, is collected using the [ingestr](https://stineb.github.io/ingestr/) package. A brief description for how to use it for our present application is provided here.

### Climate forcing

This extracts from original WATCH-WFDEI files, provided as NetCDF (global, 0.5 degree resolution), provided as monthly files containing all days in each month. The data directory specified here (`dir = "~/data/watch_wfdei/"`) contains sub-directories with names corresponding to ingestr standard names (e.g., `"temp"`). The variables for which data is to be ingested, is given by the argument `getvars`. See the [ingestr](https://stineb.github.io/ingestr/) website for a list of all standard variable names. For P-model simulations with rsofun, we typically use the variables indicated below. An additional variable (cloud cover fraction) is read from CRU TS data, for which a data ingest option is also available in the ingestr package.

For multiple sites, data is ingested as follows.

```{r message=FALSE, warning=FALSE, eval=FALSE}
ddf_watch <- ingest(
  siteinfo = siteinfo,
  source    = "watch_wfdei",
  getvars   = c("temp", "prec", "ppfd", "vpd"),
  dir       = "~/data/watch_wfdei/"  # adjust this with your local path
)

ddf_cru <- ingest(
  siteinfo = siteinfo,
  source    = "cru",
  getvars   = "ccov",
  dir       = "~/data/cru/ts_4.01/"  # adjust this with your local path
)
```

The data objects `ddf_watch` and `ddf_cru` are organised as a nested table with rows for sites and time series nested inside the column `data`. See [here](https://tidyr.tidyverse.org/reference/nest.html) for how to handle nested data frames.

Note that climate data extraction for a large number of sites takes a long time to complete and (irrespective of the number of sites for which data is extracted) requires original data files (WATCH-WFDEI and CRU TS) to be stored and accessible locally.

For internals of [CES, ETH Zurich](https://computationales.ethz.ch/): It is advisable to run this on the Euler HPC. For this, create an R script containing above code plus library load and file saving statements (e.g. as `rscript_get_watch_cru.R`), and send it as a job to the cluster by the following command, entered in the terminal:

```{sh eval = FALSE}
bsub -u username -J get_watch_cru -R "rusage[mem=25000]" "Rscript --vanilla rscript_get_watch_cru.R"
```

Now, Combine the two meteo data frames into one, containing `ccov` (cloud cover) from CRU and all other variables from WATCH-WFDEI

```{r eval=FALSE}
ddf_meteo <- df_watch %>% 
  tidyr::unnest(data) %>% 
  left_join(
    ddf_cru %>% 
      tidyr::unnest(data),
    by = c("sitename", "date")
  ) %>% 
  group_by(sitename) %>% 
  tidyr::nest()
```

### fAPAR forcing

fAPAR data is prescribed in the P-model setup. MODIS data can be ingested either using the [MODISTools](https://docs.ropensci.org/MODISTools/) R package from MODIS LP DAAC (see a complete description [here](https://stineb.github.io/ingestr/articles/example.html#modis-lp-daac-1)), or from MODIS data hosted on Google Earth Engine using the [gee_subset](https://github.com/bluegreen-labs/gee_subset) R package. The former provides full functionality for extracting data for larger areas, including multiple pixels. The latter works much faster but allows only data ingest for single pixels. Choose the appropriate option for your application. Both are available through the [ingestr](https://stineb.github.io/ingestr/) R package and an example is provided below.

Note that the P-model provides predictions also for leaf-level quantities (acclimated Vcmax and Jmax). These are independent of fAPAR. Hence, this step can be skipped and the fAPAR forcing set to 1.0 for all dates. To get an object in the required standard format, use `ingest` once more, this time with `source = "fapar_unity"`:

```{r}
ddf_fapar_unity <- ingest(
  siteinfo  = siteinfo,
  source    = "fapar_unity"
  )

ddf_fapar_unity$data[[1]] %>% head()
```

#### MODISTools

The following example is for downloading MODIS collection 6, MCD15A3H, band `Fpar_500m` data.

```{r eval=FALSE}
settings_modis <- get_settings_modis(
  bundle            = "modis_fpar",
  data_path         = "~/data/modis_subsets/",
  method_interpol   = "loess",
  keep              = TRUE,
  overwrite_raw     = FALSE,
  overwrite_interpol= TRUE,
  n_focal           = 0
  )

df_modis_fpar <- ingest(
  siteinfo, 
  source = "modis",
  settings = settings_modis, 
  parallel = FALSE,
  ncores = 2  # allows parallelised download
  )
```

To make this output consistent for use below, let's nest it and rename the desired column to `fapar` (this is a bit weird, sorry)

```{r eval=FALSE}
df_modis_fpar <- df_modis_fpar %>% 
  rename(fapar = modisvar_filled) %>%
  group_by(sitename) %>% 
  nest()
```

#### gee_subsets

This requires authentication with Google Earth Engine. See [here](https://stineb.github.io/ingestr/articles/example.html#google-earth-engine) for a guide of required steps. Once this is done, do the following.

```{r warning=FALSE, message=FALSE}
settings_gee <- get_settings_gee(
  bundle            = "modis_fpar",
  python_path       = system("which python", intern = TRUE),
  gee_path          = "~/google_earth_engine_subsets/gee_subset/", 
  data_path         = "~/data/gee_subsets/",    # adjust this with your local path
  method_interpol   = "linear",
  keep              = TRUE,
  overwrite_raw     = FALSE,
  overwrite_interpol= TRUE
  )

df_gee_modis_fpar <- ingest(
  siteinfo= siteinfo,
  source  = "gee",
  settings= settings_gee,
  verbose = FALSE
  )
```

### CO2 forcing

Ingesting CO2 data is particularly simple. We can safely assume it's well mixed in the atmosphere (independent of site location), and we can use a annual mean value for all days in respective years.

```{r}
df_co2 <- ingestr::ingest(
  siteinfo,
  source  = "co2_mlo",
  verbose = FALSE
  )
```

## Network site ensemble

In this case, sites are not identified by their longitude and latitude, but by site names, that follow a standard, given by the site network. Preparing forcing data, calibrating, and evaluating rsofun is made particularly easy for FLUXNET simulations. Site meta information for FLUXNET is provided through the ingestr package:

```{r}
siteinfo_fluxnet2015
```

Note that `year_start` and `year_end` are for data available through the FLUXNET2015 distribution, and the ensemble of sites corresponds to those for which data is made available open access (Tier 1).

### Climate forcing

The following ingests meteorological data from the FLUXNET 2015 files for variables daytime temperature, precipitation, daytime VPD, shortwave incoming radiation, net radiation, and atmospheric pressure. Arguments that are specific for this data source are provided in the `settings` list. Unfortunately, FLUXNET 2015 doesn't provide daytime VPD. But we can derive it using the ingestr R package as described [here](https://stineb.github.io/ingestr/articles/calc_daytime_vpd.html) and done below. This writes files with daytime VPD into the directory specified by `settings_fluxnet$dir_hh`. The data object `ddf_fluxnet` is organised as a nested table with rows for sites and time series nested inside the column `data`. See [here](https://tidyr.tidyverse.org/reference/nest.html) for how to handle nested dataframes.

```{r message=FALSE, warning=FALSE}
library(ingestr)
ddf_fluxnet <- ingestr::ingest(
  siteinfo  = siteinfo,
  source    = "fluxnet",
  getvars   = list(temp = "TA_F_DAY", prec = "P_F", vpd  = "VPD_F_DAY", ppfd = "SW_IN_F", patm = "PA_F"),
  dir       = "~/data/FLUXNET-2015_Tier1/20191024/DD/",
  settings  = list(dir_hh = "~/data/FLUXNET-2015_Tier1/20191024/HH/", getswc = FALSE),
  timescale = "d"
  )
```

Some meteo data is not available from FLUXNET. Extract it from CRU global climate files instead.

```{r}
ddf_cru <- ingestr::ingest(
  siteinfo  = siteinfo,
  source    = "cru",
  getvars   = list(ccov = "cld"),
  dir       = "~/data/cru/ts_4.01/"
  )
```

Combine the two meteo data frames into one, containing `ccov` (cloud cover) from CRU and all other variables from FLUXNET.

```{r}
ddf_meteo <- ddf_fluxnet %>% 
  tidyr::unnest(data) %>% 
  left_join(
    ddf_cru %>% 
      tidyr::unnest(data),
    by = c("sitename", "date")
  ) %>% 
  group_by(sitename) %>% 
  tidyr::nest()
```

### fAPAR forcing

fAPAR data is not provided specifically for site networks. Instead, to get the data given the longitude and latitude of sites, follow the same instructions as described above for the no-network case.

## Simulation settings

This and all subsequent sections are not specific to whether you're doing a network or no-network site ensemble.

Specify additional simulation parameters that are identical for all site-scale simulations in multi-site runs,

```{r}
params_siml <- list(
  spinup             = TRUE,      # to bring soil moisture to steady state
  spinupyears        = 10,        # number of spinup years. 10 is enough for soil moisture.
  recycle            = 1,         # number of years recycled during spinup 
  soilmstress        = FALSE,     # boolean for whether soil moisture stress function is included
  tempstress         = FALSE,     # boolean for whether temperature stress function is included
  calc_aet_fapar_vpd = FALSE,     # set to FALSE - should be dropped again
  in_ppfd            = TRUE,      # if available from forcing files, set to TRUE
  in_netrad          = FALSE     # if available from forcing files, set to TRUE
  )
```

<!-- Run `prepare_setup_sofun()` to define the simulation settings that contain all the information specified by the two steps above (meta info, and simulation parameters), global simulation parameters are wrapped inside an additional column `params_siml`, added to the site meta info dataframe. -->

<!-- ```{r} -->

<!-- siteinfo <- prepare_setup_sofun(siteinfo = siteinfo, params_siml = params_siml) -->

<!-- ``` -->

## Define model parameters

Specify model parameters based on prior model calibration. See `benchmarking/tag_v*/benchmark_gpp_FLUXNET2015_ensemble.html` for latest calibrations.

```{r}
params_modl <- list(
  kphio           = 0.09423773,
  soilm_par_a     = 0.33349283,
  soilm_par_b     = 1.45602286
  )
```

## Define soil parameters

For now, this is implemented as an illustration. Should be made site-specific. Values entered here take no effect.

```{r}
df_soiltexture <- bind_rows(
  top    = tibble(layer = "top",    fsand = 0.4, fclay = 0.3, forg = 0.1, fgravel = 0.1),
  bottom = tibble(layer = "bottom", fsand = 0.4, fclay = 0.3, forg = 0.1, fgravel = 0.1)
)
```

## Collect all drivers

Finally, we can collect forcing data, simulation parameters, and site meta info into a single object that will be used to drive rsofun. All of the above steps can be customized. The function `collect_drivers_sofun()` can in general be used to process forcing data into the format required to run SOFUN. The arguments must have the following form:

-   `siteinfo`: A data frame (tibble) with columns `sitename`, `lon`, `lat`, `elv` (elevation), `year_start`, `year_end`, `whc` (water holding capacity used for simulating the soil water balance). We have created this above.

```{r}
siteinfo
```

-   `meteo`: A nested data frame with columns `sitename` and `data`. The latter contains the nested meteorological forcing data frames, with columns `date`, `temp`, `prec`, `vpd`, `ppfd`, `patm`, and `ccov`. Like this:

```{r}
## nested data frame:
ddf_meteo

## inside .$data:
ddf_meteo$data[[1]] %>% dplyr::select(-ccov_int)
```

-   `fapar`: A nested data frame with columns `sitename` and `data`. The latter contains the nested meteorological forcing data frames, with columns `date`, and `fapar`. Like this:

```{r}
## nested data frame:
df_modis_fpar

## inside .$data:
df_modis_fpar$data[[1]] %>% dplyr::select(date, fapar)
```

-   `co2` : A nested data frame with columns `sitename` and `data`. The latter contains the nested meteorological forcing data frames, with columns `date`, and `co2`. Like this:

```{r}
## nested data frame:
df_co2

## inside .$data:
df_co2$data[[1]] %>% dplyr::select(date, co2)
```

-   `df_soiltexture`: See above ('Define soil parameters')

See [here](https://tidyr.tidyverse.org/reference/nest.html) for how to handle nested dataframes.

Finally, all input data can be collected by:

```{r}
df_drivers <- collect_drivers_sofun( 
  siteinfo       = siteinfo,
  params_siml    = params_siml,
  meteo          = ddf_meteo, 
  fapar          = df_modis_fpar,
  co2            = df_co2,
  df_soiltexture = df_soiltexture
  )
df_drivers
```

## Run model

Finally, run the model for a set of sites.

```{r}
df_output <- runread_pmodel_f(
     df_drivers, 
     params_modl = params_modl, 
     makecheck = TRUE,
     parallel = FALSE
     )
```
